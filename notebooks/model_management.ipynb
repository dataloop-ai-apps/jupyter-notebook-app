{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Management\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get the dataset\n",
        "\n",
        "A dataset is a bucket collection of Items (files), their metadata and annotations. It can have a file-system-like structure with folders and subfolders at any level. A dataset is mapped to a Driver (which derives from an Integration), to contain items synced from external cloud storage. Dataset versioning actions include cloning and merging.\n",
        "\n",
        "We will be using the datasets that we have already set up for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dtlpy as dl\n",
        "\n",
        "# project_id is automatically set by the notebook \n",
        "project_id = 'project_id'\n",
        "\n",
        "project = dl.projects.get(project_id=project_id)\n",
        "\n",
        "dataset = project.datasets.get(dataset_name=\"V2 Plant Seedlings Dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Model Get"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = project.models.get(model_name='pretrained-resnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Model deploy\n",
        "\n",
        "In case that the model is already ready for production, deploy it by the following command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.deploy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Clone Model\n",
        "\n",
        "To train the pretrained model, we need to clone existing model first and add the dataset, that will be used for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "clone_model = model.clone(model_name='my pretrained resnet',\n",
        "                          dataset=dataset,\n",
        "                          description='pretrained cloned into my project')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Model Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To train a model on a dataset we need to add the train and validation filters to the model, that will help to split the data to train and validation dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_filters = dl.Filters(field=\"metadata.system.tags.train\", values=True)\n",
        "validation_filters = dl.Filters(field=\"metadata.system.tags.validation\", values=True)\n",
        "\n",
        "clone_model.add_subset(subset_name=\"train\", subset_filter=train_filters)\n",
        "clone_model.add_subset(subset_name=\"validation\", subset_filter=validation_filters)\n",
        "clone_model.update(system_metadata=True)\n",
        "\n",
        "execution = clone_model.train(service_config={\n",
        "    \"name\": \"resnet-train-evaluate\",\n",
        "    \"runtime\": {\n",
        "        \"podType\": \"regular-m\",\n",
        "        \"concurrency\": 1,\n",
        "        \"runnerImage\": \"gcr.io/viewo-g/piper/agent/runner/apps/torch-models:0.1.4\",\n",
        "        \"autoscaler\": {\n",
        "            \"type\": \"rabbitmq\",\n",
        "            \"minReplicas\": 0,\n",
        "            \"maxReplicas\": 2,\n",
        "            \"queueLength\": 100\n",
        "        }\n",
        "    }\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Wait for the training to finish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "execution.wait()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Model Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, get the spesifc item we want to perfrom prediction with our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "item_filename = '/Black-grass/6.png'\n",
        "\n",
        "item = dataset.items.get(filepath=item_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the model predict method on the item.\n",
        "\n",
        "Notice: Since the predict method expect to recive a list of item ids, we will add the item id to a list that will be sent to the method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clone_model.predict(item_ids=[item.id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Model Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice: To evaluate a model we need to:\n",
        "1. Get a dataset, that will be used for the evaluation.\n",
        "2. Define the test filters, to build the test dataloader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_filters = dl.Filters(field='metadata.system.tags.test', values=True)\n",
        "\n",
        "clone_model.evaluate(dataset_id=dataset.id,\n",
        "                     filters=test_filters)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
